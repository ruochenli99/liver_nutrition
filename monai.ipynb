{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# data_process & environment"],"metadata":{"id":"jXaxB3ilI5_d"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bn_cM9ngJCrX","executionInfo":{"status":"ok","timestamp":1734810620908,"user_tz":-60,"elapsed":2181,"user":{"displayName":"RuoChen Li","userId":"07743281955741522511"}},"outputId":"a1ecae91-1db8-452d-89d6-4bcf00aa4908"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n"],"metadata":{"id":"VXZS6uE9Nn-M","executionInfo":{"status":"ok","timestamp":1734810620908,"user_tz":-60,"elapsed":3,"user":{"displayName":"RuoChen Li","userId":"07743281955741522511"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3e8da8b-72ab-429a-fa00-7670844911f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00ksgpwlIqIL"},"outputs":[],"source":["!pip install -q \"monai-weekly[nibabel, tqdm]\""]},{"cell_type":"code","source":["import logging\n","import os\n","import sys\n","import shutil\n","import tempfile\n","\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.utils.tensorboard import SummaryWriter\n","import numpy as np\n","\n","import monai\n","from monai.apps import download_and_extract\n","from monai.config import print_config\n","from monai.data import DataLoader, ImageDataset\n","from monai.transforms import (\n","    EnsureChannelFirst,\n","    Compose,\n","    RandRotate90,\n","    Resize,\n","    ScaleIntensity,\n",")\n","\n","pin_memory = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n","print_config()"],"metadata":{"id":"Rb91g4V2TuJS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734810623212,"user_tz":-60,"elapsed":7,"user":{"displayName":"RuoChen Li","userId":"07743281955741522511"}},"outputId":"702957d4-6c87-4c52-dddd-001508a7253e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MONAI version: 1.5.dev2450\n","Numpy version: 1.26.4\n","Pytorch version: 2.5.1+cu121\n","MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n","MONAI rev id: 0726cee7ba6c1b31f34d54fc26fe6b8db5f5c79c\n","MONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n","\n","Optional dependencies:\n","Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n","ITK version: NOT INSTALLED or UNKNOWN VERSION.\n","Nibabel version: 5.3.2\n","scikit-image version: 0.25.0\n","scipy version: 1.13.1\n","Pillow version: 11.0.0\n","Tensorboard version: 2.17.1\n","gdown version: 5.2.0\n","TorchVision version: 0.20.1+cu121\n","tqdm version: 4.67.1\n","lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n","psutil version: 5.9.5\n","pandas version: 2.2.2\n","einops version: 0.8.0\n","transformers version: 4.47.1\n","mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n","pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n","clearml version: NOT INSTALLED or UNKNOWN VERSION.\n","\n","For details about installing the optional dependencies, please visit:\n","    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n","\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","\n","# Define the root directory\n","root_dir = \"/content/drive/MyDrive/yufei/monaidata\"\n","\n","# Load the label file\n","label_file = os.path.join(root_dir, \"LABEL0814.xlsx\")\n","labels_df = pd.read_excel(label_file, header=None, names=[\"id\", \"label\"])\n","\n","# Load the train and test tables\n","train_file = \"/content/drive/MyDrive/yufei/data/train.xlsx\"\n","test_file = \"/content/drive/MyDrive/yufei/data/test.xlsx\"\n","\n","train_df = pd.read_excel(train_file, header=0, names=[\"id\", \"label\"])\n","test_df = pd.read_excel(test_file, header=0, names=[\"id\", \"label\"])\n","\n","# Get all image files\n","image_files = os.listdir(root_dir)\n","image_files = [f for f in image_files if f.endswith(\".nii\")]\n","\n","# Initialize the image path and tag list\n","train_images, train_labels = [], []\n","test_images, test_labels = [], []\n","\n","\n","# Iterate over all image files\n","for image_file in image_files:\n","    # Extract patient ID\n","    id = \"_\".join(image_file.split('_')[:3])\n","\n","    # Find the corresponding tag\n","    label_row = labels_df[labels_df['id'] == id]\n","\n","    if label_row.empty:\n","        print(f\"Warning: No matching label found for ID {id}\")\n","    else:\n","        # Check if the ID belongs to train or tests\n","        if id in train_df['id'].values:\n","            # print(f\"Adding {id} to train set\")\n","            train_images.append(os.path.join(root_dir, image_file))\n","            train_labels.append(label_row['label'].values[0])\n","        elif id in test_df['id'].values:\n","            # print(f\"Adding {id} to test set\")\n","            test_images.append(os.path.join(root_dir, image_file))\n","            test_labels.append(label_row['label'].values[0])\n","        else:\n","            print(f\"ID {id} not found in train or test split.\")\n","\n","\n","# Debug: output warnings for empty training or test sets\n","if len(train_labels) == 0:\n","    print(\"Warning: No labels found for the training set.\")\n","if len(test_labels) == 0:\n","    print(\"Warning: No labels found for the test set.\")\n","\n","# One-hot coding training set labels\n","if len(train_labels) > 0:\n","    train_labels_tensor = torch.as_tensor(train_labels, dtype=torch.int64)\n","    train_labels_one_hot = torch.nn.functional.one_hot(train_labels_tensor).float()\n","    # print(\"Train Labels (One-Hot):\", train_labels_one_hot)\n","else:\n","    print(\"No train labels to encode.\")\n","\n","# One-hot coding test set tags\n","if len(test_labels) > 0:\n","    test_labels_tensor = torch.as_tensor(test_labels, dtype=torch.int64)\n","    test_labels_one_hot = torch.nn.functional.one_hot(test_labels_tensor).float()\n","    # print(\"Test Labels (One-Hot):\", test_labels_one_hot)\n","else:\n","    print(\"No test labels to encode.\")\n","\n","print(len(train_images), len(train_labels))\n","print(len(test_images), len(test_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDZ-lnsNsSfV","executionInfo":{"status":"ok","timestamp":1734810624614,"user_tz":-60,"elapsed":1406,"user":{"displayName":"RuoChen Li","userId":"07743281955741522511"}},"outputId":"6c196d53-5559-4ff6-cc7a-b9d0b2cfd4fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["187 187\n","80 80\n"]}]},{"cell_type":"code","source":["class CustomImageDataset(ImageDataset):\n","    def __getitem__(self, index):\n","        # Get filenames and tags\n","        img_file = self.image_files[index]\n","        label = self.labels[index]\n","\n","        # Load the image and transform it\n","        img = self.loader(img_file)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return img, label, img_file  # Return images, labels, and image filenames\n"],"metadata":{"id":"UrJUVJTgKZhl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","random_seed = 42\n","# Define transforms\n","train_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize((96, 96, 32)), RandRotate90()])\n","val_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize((96, 96, 32))])\n","bz=4\n","\n","# Create train dataset and dataloader\n","train_ds = CustomImageDataset(image_files=train_images, labels=train_labels, transform=train_transforms)\n","train_loader = DataLoader(train_ds, batch_size=bz, shuffle=True, num_workers=2, pin_memory=pin_memory)\n","\n","# Create test (validation) dataset and dataloader\n","val_ds = CustomImageDataset(image_files=test_images, labels=test_labels, transform=val_transforms)\n","val_loader = DataLoader(val_ds, batch_size=bz, shuffle=False, num_workers=2, pin_memory=pin_memory)\n","\n","# Check dataset for debugging purposes\n","check_ds = ImageDataset(image_files=train_images, labels=train_labels, transform=train_transforms)\n","check_loader = DataLoader(check_ds, batch_size=bz, num_workers=2, pin_memory=pin_memory)\n","\n","# Print first batch for debugging\n","im, label = monai.utils.misc.first(check_loader)\n","print(type(im), im.shape, label, label.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nh7uFm8QjyoJ","executionInfo":{"status":"ok","timestamp":1734810625647,"user_tz":-60,"elapsed":1035,"user":{"displayName":"RuoChen Li","userId":"07743281955741522511"}},"outputId":"78a43c88-3602-4c5b-f258-137859bcd51c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'monai.data.meta_tensor.MetaTensor'> torch.Size([4, 1, 96, 96, 32]) tensor([0, 0, 0, 0]) torch.Size([4])\n"]}]},{"cell_type":"code","source":["class FocalLoss(torch.nn.Module):\n","    def __init__(self, gamma=2, alpha=None):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","\n","    def forward(self, inputs, targets):\n","\n","        BCE_loss = torch.nn.functional.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-BCE_loss)\n","        if self.alpha is not None:\n","            at = self.alpha.gather(0, targets)\n","            BCE_loss = at * BCE_loss\n","        F_loss = ((1 - pt) ** self.gamma * BCE_loss).mean()\n","        return F_loss\n"],"metadata":{"id":"TBQZCcaRgWpR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model: DenseNet121"],"metadata":{"id":"4pnKoVrBJBMN"}},{"cell_type":"code","source":["import torch\n","from collections import Counter\n","from torch.utils.tensorboard import SummaryWriter\n","import monai\n","\n","# Create DenseNet121 models, loss functions, and optimizers\n","model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n","\n","# Weighted cross-entropy loss\n","loss_function = FocalLoss(alpha=torch.tensor([172, 95]).to(device))\n","# optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","\n","# Add learning rate scheduler\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n","\n","# Training and validating hyperparameters\n","val_interval = 2\n","best_metric = -1\n","best_metric_epoch = -1\n","epoch_loss_values = []\n","metric_values = []\n","writer = SummaryWriter()\n","max_epochs = 50\n","best_train_results = []\n","best_val_results = []\n","\n","for epoch in range(max_epochs):\n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch + 1}/{max_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","    train_epoch_results = []  # Store the training results for the current epoch\n","    for batch_data in train_loader:\n","        step += 1\n","        inputs, labels, img_names = batch_data[0].to(device), batch_data[1].to(device), batch_data[2]\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_len = len(train_ds) // train_loader.batch_size\n","        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n","\n","        predicted_labels = outputs.argmax(dim=1)\n","        probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Convert raw logits to probabilities\n","\n","        # Save the results of the training set for the current epoch\n","        for i in range(len(img_names)):\n","            train_epoch_results.append(\n","                (img_names[i], labels[i].item(), predicted_labels[i].item(), probabilities[i].cpu().tolist())\n","            )\n","\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        num_correct = 0.0\n","        metric_count = 0\n","        val_epoch_results = []   # Store the validation results for the current epoch\n","        for val_data in val_loader:\n","            val_images, val_labels, val_img_names = val_data[0].to(device), val_data[1].to(device), val_data[2]\n","            with torch.no_grad():\n","                val_outputs = model(val_images)\n","                predicted_val_labels = val_outputs.argmax(dim=1)\n","                probabilities = torch.nn.functional.softmax(val_outputs, dim=1)  # Convert raw logits to probabilities\n","                value = torch.eq(predicted_val_labels, val_labels)\n","                metric_count += len(value)\n","                num_correct += value.sum().item()\n","\n","                # Save the validation set results for the current epoch\n","                for i in range(len(val_img_names)):\n","                    val_epoch_results.append(\n","                        (val_img_names[i], val_labels[i].item(), predicted_val_labels[i].item(), probabilities[i].cpu().tolist())\n","                    )\n","\n","        metric = num_correct / metric_count\n","        metric_values.append(metric)\n","\n","       # If current accuracies are better, update training and validation results of the best models\n","        if metric > best_metric:\n","            best_metric = metric\n","            best_metric_epoch = epoch + 1\n","            torch.save(model.state_dict(), \"best_metric_model_classification3d_dense.pth\")\n","            print(\"saved new best metric model\")\n","\n","             # Update the results of the best training and validation sets\n","            best_train_results = train_epoch_results\n","            best_val_results = val_epoch_results\n","\n","        print(f\"Current epoch: {epoch + 1} current accuracy: {metric:.4f}\")\n","        print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n","        writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n","\n","        # Invoke the learning rate scheduler to adjust the learning rate based on validation set accuracies\n","        scheduler.step(metric)\n","\n","print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","\n","# Print the results of the training and validation sets for the best epochs\n","print(\"\\nBest epoch train results:\")\n","for img_name, true_label, pred_label, probabilities in best_train_results:\n","    print(f\"Train Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {probabilities}\")\n","\n","print(\"\\nBest epoch validation results:\")\n","for img_name, true_label, pred_label, probabilities in best_val_results:\n","    print(f\"Val Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {probabilities}\")\n","\n","writer.close()\n"],"metadata":{"id":"AYVTiBJFJFU9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model: ResNet"],"metadata":{"id":"J7OIwybk8VuC"}},{"cell_type":"code","source":["import monai.networks.nets as nets\n","\n","# Create a ResNet model using MONAI with basic block, 3D data, input channels as 1, and output classes as 2\n","model = nets.ResNet(\n","    block=\"basic\",            # ResNet block type\n","    layers=[2, 2, 2, 2],      # Number of layers in each block (ResNet18 configuration)\n","    block_inplanes=[64, 128, 256, 512],  # Define the number of filters in each block\n","    spatial_dims=3,           # 3D convolution\n","    n_input_channels=1,       # Input channels (for grayscale/1 channel data)\n","    num_classes=2,            # Output classes\n","    conv1_t_size=7,           # First convolution kernel size\n","    conv1_t_stride=2          # First convolution stride\n",").to(device)\n","\n","loss_function = FocalLoss(alpha=torch.tensor([172, 95]).to(device))\n","# optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","\n","# Add learning rate scheduler\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n","\n","\n","# Training and validating hyperparameters\n","val_interval = 2\n","best_metric = -1\n","best_metric_epoch = -1\n","epoch_loss_values = []\n","metric_values = []\n","writer = SummaryWriter()\n","max_epochs = 50\n","best_train_results = []\n","best_val_results = []\n","\n","for epoch in range(max_epochs):\n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch + 1}/{max_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","    train_epoch_results = []\n","    for batch_data in train_loader:\n","        step += 1\n","        inputs, labels, img_names = batch_data[0].to(device), batch_data[1].to(device), batch_data[2]\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_len = len(train_ds) // train_loader.batch_size\n","        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n","\n","        predicted_labels = outputs.argmax(dim=1)\n","        probabilities = torch.softmax(outputs, dim=1)  # Getting a probability distribution\n","\n","        # Save the results of the training set for the current epoch (including image name, true label, predicted label and predicted probability)\n","        for i in range(len(img_names)):\n","            train_epoch_results.append((img_names[i], labels[i].item(), predicted_labels[i].item(), probabilities[i].detach().cpu().numpy()))\n","\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        num_correct = 0.0\n","        metric_count = 0\n","        val_epoch_results = []  # Store the validation results for the current epoch\n","        for val_data in val_loader:\n","            val_images, val_labels, val_img_names = val_data[0].to(device), val_data[1].to(device), val_data[2]\n","            with torch.no_grad():\n","                val_outputs = model(val_images)\n","                predicted_val_labels = val_outputs.argmax(dim=1)\n","                probabilities = torch.softmax(val_outputs, dim=1)\n","                value = torch.eq(predicted_val_labels, val_labels)\n","                metric_count += len(value)\n","                num_correct += value.sum().item()\n","\n","                # Save validation set results for the current epoch (including image name, true label, predicted label and predicted probability)\n","                for i in range(len(val_img_names)):\n","                    val_epoch_results.append((val_img_names[i], val_labels[i].item(), predicted_val_labels[i].item(), probabilities[i].detach().cpu().numpy()))\n","\n","        metric = num_correct / metric_count\n","        metric_values.append(metric)\n","\n","        # If current accuracies are better, update training and validation results of the best models\n","        if metric > best_metric:\n","            best_metric = metric\n","            best_metric_epoch = epoch + 1\n","            torch.save(model.state_dict(), \"best_metric_model_classification3d_res.pth\")\n","            print(\"saved new best metric model\")\n","\n","            # Update the results of the best training and validation sets\n","            best_train_results = train_epoch_results\n","            best_val_results = val_epoch_results\n","\n","        print(f\"Current epoch: {epoch + 1} current accuracy: {metric:.4f}\")\n","        print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n","        writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n","        scheduler.step(metric)\n","\n","print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","\n","# Print the results of the training and validation sets for the best epochs\n","print(\"\\nBest epoch train results:\")\n","for img_name, true_label, pred_label, prob in best_train_results:\n","    print(f\"Train Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {prob}\")\n","\n","print(\"\\nBest epoch validation results:\")\n","for img_name, true_label, pred_label, prob in best_val_results:\n","    print(f\"Val Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {prob}\")\n","\n","writer.close()\n","\n"],"metadata":{"id":"aAtaZayjhvl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# VIT\n"],"metadata":{"id":"g5Wsk2G60RwG"}},{"cell_type":"code","source":["import torch\n","from torch.utils.tensorboard import SummaryWriter\n","from monai.networks.nets import ViT\n","import json\n","\n","# Create the ViT model\n","model = ViT(\n","    in_channels=1,\n","    img_size=(96, 96, 32),\n","    patch_size=(16, 16, 8),\n","    hidden_size=768,\n","    mlp_dim=3072,\n","    num_layers=12,\n","    num_heads=12,\n","    classification=True,\n","    num_classes=2,\n","    spatial_dims=3\n",").to(device)\n","\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n","\n","# Training and validating hyperparameters\n","val_interval = 2\n","best_metric = -1\n","best_metric_epoch = -1\n","epoch_loss_values = []\n","metric_values = []\n","writer = SummaryWriter()\n","max_epochs = 50\n","\n","best_train_results = []\n","best_val_results = []\n","\n","def save_results_to_file(results, filename):\n","    formatted_results = []\n","    for img_name, true_label, pred_label, prob in results:\n","        formatted_results.append({\n","            \"Image\": img_name,\n","            \"True Label\": true_label,\n","            \"Predicted Label\": pred_label,\n","            \"Probabilities\": prob.tolist()\n","        })\n","    with open(filename, \"w\") as f:\n","        json.dump(formatted_results, f, indent=4)\n","\n","for epoch in range(max_epochs):\n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch + 1}/{max_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","\n","    train_epoch_results = []\n","\n","    for batch_data in train_loader:\n","        step += 1\n","        inputs, labels, img_names = batch_data[0].to(device), batch_data[1].to(device), batch_data[2]  # 获取输入、标签和图像名\n","        optimizer.zero_grad()\n","        outputs, _ = model(inputs)  # Get the model's classification output\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","        # Save file name, true label, predicted label and predicted probability for each image\n","        predicted_labels = outputs.argmax(dim=1)\n","        probabilities = torch.softmax(outputs, dim=1)\n","        for i in range(len(img_names)):\n","            train_epoch_results.append((\n","                img_names[i],\n","                labels[i].item(),\n","                predicted_labels[i].item(),\n","                probabilities[i].detach().cpu().numpy()\n","            ))\n","\n","        epoch_len = len(train_ds) // train_loader.batch_size\n","        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n","\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        num_correct = 0.0\n","        metric_count = 0\n","        val_epoch_results = []\n","\n","        for val_data in val_loader:\n","            val_images, val_labels, val_img_names = val_data[0].to(device), val_data[1].to(device), val_data[2]  # Get validation data and image name\n","            with torch.no_grad():\n","                val_outputs, _ = model(val_images)\n","                predicted_val_labels = val_outputs.argmax(dim=1)\n","                probabilities = torch.softmax(val_outputs, dim=1)\n","                value = torch.eq(predicted_val_labels, val_labels)\n","                metric_count += len(value)\n","                num_correct += value.sum().item()\n","\n","                # Save the filename, true label, predicted label and predicted probability of the validation set\n","                for i in range(len(val_img_names)):\n","                    val_epoch_results.append((\n","                        val_img_names[i],\n","                        val_labels[i].item(),\n","                        predicted_val_labels[i].item(),\n","                        probabilities[i].detach().cpu().numpy()\n","                    ))\n","\n","        metric = num_correct / metric_count\n","        metric_values.append(metric)\n","\n","        # Best models and results preserved\n","        if metric > best_metric:\n","            best_metric = metric\n","            best_metric_epoch = epoch + 1\n","            torch.save(model.state_dict(), \"best_metric_model_classification3d_vit.pth\")\n","            print(\"saved new best metric model\")\n","\n","            # Update the results of the best training and validation sets\n","            best_train_results = train_epoch_results\n","            best_val_results = val_epoch_results\n","\n","        print(f\"Current epoch: {epoch + 1} current accuracy: {metric:.4f}\")\n","        print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n","        writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n","\n","# Print the results of the training and validation sets for the best epochs\n","print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","\n","\n","save_results_to_file(best_train_results, \"best_train_results.json\")\n","save_results_to_file(best_val_results, \"best_val_results.json\")\n","\n","print(\"\\nBest epoch train results:\")\n","for img_name, true_label, pred_label, prob in best_train_results:\n","    print(f\"Train Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {prob}\")\n","\n","print(\"\\nBest epoch validation results:\")\n","for img_name, true_label, pred_label, prob in best_val_results:\n","    print(f\"Val Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {prob}\")\n","\n","writer.close()\n"],"metadata":{"id":"IbtYnJQV0UJu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ResNetFeatures+XGboost/FC"],"metadata":{"id":"065MuRgC8aSR"}},{"cell_type":"code","source":["import torch\n","import monai\n","import numpy as np\n","import xgboost as xgb\n","\n","# Initialize ResNetFeatures\n","model = monai.networks.nets.ResNetFeatures(\n","    model_name=\"resnet18\",  # It could be resnet10, resnet18, resnet34, etc. #\n","    pretrained=True,\n","    spatial_dims=3,         # 3D data\n","    in_channels=1\n",").to(device)\n","\n","\n","model.eval()\n","\n","# Extract the features\n","def extract_features(model, loader):\n","    features_list = []\n","    labels_list = []\n","\n","    with torch.no_grad():\n","        for batch_data in loader:\n","            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n","\n","            features = model(inputs)  # Get a list of features\n","            final_features = features[-1]  # Select the last layer of features\n","\n","            # Spread features to 2D: [batch_size, n_features]\n","            final_features = final_features.view(final_features.size(0), -1)\n","\n","            features_list.append(final_features.cpu().numpy())\n","            labels_list.append(labels.cpu().numpy())\n","\n","    features_array = np.concatenate(features_list, axis=0)\n","    labels_array = np.concatenate(labels_list, axis=0)\n","\n","    return features_array, labels_array\n"],"metadata":{"id":"zvyddFtskHve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["XGBOOST"],"metadata":{"id":"0Kcf_HIHqPUW"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import VotingClassifier\n","import xgboost as xgb\n","\n","# Initialize the classifier\n","xgb_classifier = xgb.XGBClassifier(\n","    objective=\"binary:logistic\",\n","    eval_metric=\"logloss\",\n","    use_label_encoder=False\n",")\n","\n","svm_classifier = SVC(probability=True)  # Using SVM classifiers\n","logreg_classifier = LogisticRegression()  # Using logistic regression classifiers\n","\n","# Soft voting fusion of three classifiers\n","voting_classifier = VotingClassifier(\n","    estimators=[\n","        ('xgb', xgb_classifier),\n","        ('svm', svm_classifier),\n","        ('logreg', logreg_classifier)\n","    ],\n","    voting='soft'  # Soft voting (using probability weighting)\n",")\n","\n","# Extract features\n","train_features, train_labels = extract_features(model, train_loader)\n","val_features, val_labels = extract_features(model, val_loader)\n","\n","# Training fusion models\n","voting_classifier.fit(train_features, train_labels)\n","\n","# Predictions on validation sets\n","val_predictions = voting_classifier.predict(val_features)\n","val_probabilities = voting_classifier.predict_proba(val_features)\n","\n","# Calculation accuracy\n","accuracy = np.mean(val_predictions == val_labels)\n","print(f\"Validation Accuracy with Soft Voting: {accuracy:.4f}\")\n","\n","# Print the predictions for each sample\n","for i in range(len(val_labels)):\n","    true_label = val_labels[i]\n","    predicted_label = val_predictions[i]\n","    probability = val_probabilities[i]\n","    print(f\"Sample {i}: True Label: {true_label}, Predicted Label: {predicted_label}, Probabilities: {probability}\")\n"],"metadata":{"id":"66Mflfl9mM_l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FC layer"],"metadata":{"id":"nYzMHC5Kimxz"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import numpy as np\n","\n","# Define simple classification networks\n","class SimpleClassifier(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(SimpleClassifier, self).__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(input_size, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  #  # flatten to [batch_size, num_features] (batch size, number of features)\n","        return self.fc(x)\n","\n","# Functions for training classification networks\n","def train_classifier(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20):\n","    model.to(device)\n","    best_val_acc = 0.0\n","    best_epoch = -1\n","    best_train_predictions = []\n","    best_val_predictions = []\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        # train\n","        for batch_data in train_loader:\n","            inputs, labels, img_names = batch_data[0], batch_data[1], batch_data[2]  # 包括图像路径名\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # Forward propagation\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # Backpropagation and optimization\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","             # Calculate training accuracy\n","            _, preds = torch.max(outputs, 1)\n","            correct_train += (preds == labels).sum().item()\n","            total_train += labels.size(0)\n","\n","        avg_train_loss = running_loss / len(train_loader)\n","        train_acc = correct_train / total_train\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}] Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","        train_predictions = []\n","        val_predictions = []\n","\n","        with torch.no_grad():\n","            for batch_data in train_loader:\n","                inputs, labels, img_names = batch_data[0], batch_data[1], batch_data[2]\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = model(inputs)\n","                probabilities = torch.softmax(outputs, dim=1)\n","                _, preds = torch.max(outputs, 1)\n","\n","                for i in range(inputs.size(0)):\n","                    true_label = labels[i].item()\n","                    pred_label = preds[i].item()\n","                    prob = probabilities[i].cpu().numpy()  # Probability of obtaining each category\n","                    train_predictions.append((img_names[i], true_label, pred_label, prob))\n","\n","            for batch_data in val_loader:\n","                inputs, labels, img_names = batch_data[0], batch_data[1], batch_data[2]\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item()\n","\n","                probabilities = torch.softmax(outputs, dim=1)\n","                _, preds = torch.max(outputs, 1)\n","                correct_val += (preds == labels).sum().item()\n","                total_val += labels.size(0)\n","\n","                for i in range(inputs.size(0)):\n","                    true_label = labels[i].item()\n","                    pred_label = preds[i].item()\n","                    prob = probabilities[i].cpu().numpy() # Probability of obtaining each category\n","                    val_predictions.append((img_names[i], true_label, pred_label, prob))\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        val_acc = correct_val / total_val\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}] Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n","\n","        # Preservation of the best models\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            best_epoch = epoch + 1\n","            best_train_predictions = train_predictions\n","            best_val_predictions = val_predictions\n","            torch.save(model.state_dict(), \"best_classifier.pth\")\n","            print(\"Best model saved.\")\n","\n","    print(f\"Training completed. Best Validation Accuracy: {best_val_acc:.4f} at Epoch {best_epoch}\")\n","\n","    # Print the best training and validation results\n","    print(\"Best Training Predictions:\")\n","    for img_name, true_label, pred_label, prob in best_train_predictions:\n","        print(f\"Train Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {prob}\")\n","\n","    print(\"Best Validation Predictions:\")\n","    for img_name, true_label, pred_label, prob in best_val_predictions:\n","        print(f\"Validation Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {prob}\")\n","\n","# Initialize the classification network\n","input_size = 96 * 96 * 32  # Assuming the input features are flattened\n","num_classes = len(np.unique(train_labels))  # categories based on labels\n","classifier = SimpleClassifier(input_size=input_size, num_classes=num_classes)\n","\n","# Define loss functions and optimizers\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss(alpha=torch.tensor([172, 95]).to(device))\n","optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n","\n","# Assume train_loader and val_loader are defined and device is device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Train the classification network\n","train_classifier(classifier, train_loader, val_loader, criterion, optimizer, device, num_epochs=50)\n"],"metadata":{"id":"tNCwUa71ipDA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MLP\n"],"metadata":{"id":"vYy8nf-Hp77C"}},{"cell_type":"code","source":["class SimpleMLP(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(SimpleMLP, self).__init__()\n","        # Define two fully connected layers\n","        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n","        self.relu = torch.nn.ReLU()  # Activation function\n","        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        # Spread inputs to accommodate fully connected layers\n","        x = torch.flatten(x, 1)  # Flatten the input, keeping batch size\n","        x = self.fc1(x)  # Input -> first fully connected layer\n","        x = self.relu(x)  # Apply the ReLU activation function\n","        x = self.fc2(x)  # Layer 1 output -> Layer 2 fully connected layer\n","        return x\n","\n","# Define input parameters\n","input_size = 96 * 96 * 32\n","hidden_size = 128  # of neurons in the hidden layer, can be adjusted as needed\n","num_classes = 2  # of categories output\n"],"metadata":{"id":"QP5jWRiQGK3j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the SimpleMLP model\n","model = SimpleMLP(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes).to(device)\n","\n","\n","loss_function = torch.nn.CrossEntropyLoss()\n","# loss_function = torch.nn.BCEWithLogitsLoss()  # also works with this data\n","\n","optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n","\n","# start a typical PyTorch training\n","val_interval = 2\n","best_metric = -1\n","best_metric_epoch = -1\n","epoch_loss_values = []\n","metric_values = []\n","writer = SummaryWriter()\n","max_epochs = 50\n","\n","# Track best epoch results\n","best_train_results = []\n","best_val_results = []\n","\n","for epoch in range(max_epochs):\n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch + 1}/{max_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","    train_epoch_results = []  # Store current epoch training results\n","\n","    for batch_data in train_loader:\n","        step += 1\n","        inputs, labels, img_names = batch_data[0].to(device), batch_data[1].to(device), batch_data[2]\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_len = len(train_ds) // train_loader.batch_size\n","        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n","\n","        predicted_labels = outputs.argmax(dim=1)\n","        probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Convert raw logits to probabilities\n","\n","        # Save current epoch training results\n","        for i in range(len(img_names)):\n","            train_epoch_results.append(\n","                (img_names[i], labels[i].item(), predicted_labels[i].item(), probabilities[i].cpu().tolist())\n","            )\n","\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        num_correct = 0.0\n","        metric_count = 0\n","        val_epoch_results = []  # Store current epoch validation results\n","\n","        for val_data in val_loader:\n","            val_images, val_labels, val_img_names = val_data[0].to(device), val_data[1].to(device), val_data[2]\n","            with torch.no_grad():\n","                val_outputs = model(val_images)\n","                predicted_val_labels = val_outputs.argmax(dim=1)\n","                probabilities = torch.nn.functional.softmax(val_outputs, dim=1)  # Convert raw logits to probabilities\n","                value = torch.eq(predicted_val_labels, val_labels)\n","                metric_count += len(value)\n","                num_correct += value.sum().item()\n","\n","                # Save current epoch validation results\n","                for i in range(len(val_img_names)):\n","                    val_epoch_results.append(\n","                        (val_img_names[i], val_labels[i].item(), predicted_val_labels[i].item(), probabilities[i].cpu().tolist())\n","                    )\n","\n","        metric = num_correct / metric_count\n","        metric_values.append(metric)\n","\n","        # If current accuracy is the best, update best model results\n","        if metric > best_metric:\n","            best_metric = metric\n","            best_metric_epoch = epoch + 1\n","            torch.save(model.state_dict(), \"best_metric_model_classification3d_dense.pth\")\n","            print(\"saved new best metric model\")\n","\n","            # Update best training and validation results\n","            best_train_results = train_epoch_results\n","            best_val_results = val_epoch_results\n","\n","        print(f\"Current epoch: {epoch + 1} current accuracy: {metric:.4f}\")\n","        print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n","        writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n","\n","print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","\n","# Print best epoch results\n","print(\"\\nBest epoch train results:\")\n","for img_name, true_label, pred_label, probabilities in best_train_results:\n","    print(f\"Train Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {probabilities}\")\n","\n","print(\"\\nBest epoch validation results:\")\n","for img_name, true_label, pred_label, probabilities in best_val_results:\n","    print(f\"Val Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {probabilities}\")\n","\n","writer.close()\n"],"metadata":{"id":"jHRT0U4iG3eB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"WIkKNjAgHV_f"}},{"cell_type":"code","source":["class SimpleCNN(torch.nn.Module):\n","    def __init__(self, num_classes):\n","        super(SimpleCNN, self).__init__()\n","        # Define a three-layer convolutional network with a single channel (1 channel) for input and num_classes categories for output\n","        self.conv1 = torch.nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = torch.nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = torch.nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","\n","        # Define pooling layers for reducing the spatial dimension of the feature map\n","        self.pool = torch.nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n","\n","       # Fully connected layer, inputs are spread from convolutional layer and passed to MLP\n","        self.fc1 = torch.nn.Linear(64 * 12 * 12 * 4, 128)\n","        self.fc2 = torch.nn.Linear(128, num_classes)\n","\n","        # Activation function\n","        self.relu = torch.nn.ReLU()\n","\n","    def forward(self, x):\n","        # After three layers of convolution and pooling\n","        x = self.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = self.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = self.relu(self.conv3(x))\n","        x = self.pool(x)\n","\n","        x = torch.flatten(x, 1)  # Flatten the input to [batch_size, features]\n","\n","        # Full connectivity layer\n","        x = self.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# of classification categories defined\n","num_classes = 2\n"],"metadata":{"id":"pHTpmfu5HYDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the SimpleCNN model\n","model = SimpleCNN(num_classes=num_classes).to(device)\n","\n","# Loss function and optimizer remain the same\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n","\n","# start a typical PyTorch training\n","val_interval = 2\n","best_metric = -1\n","best_metric_epoch = -1\n","epoch_loss_values = []\n","metric_values = []\n","writer = SummaryWriter()\n","max_epochs = 50\n","\n","# Track best epoch results\n","best_train_results = []\n","best_val_results = []\n","\n","for epoch in range(max_epochs):\n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch + 1}/{max_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","    train_epoch_results = []  # Store current epoch training results\n","\n","    for batch_data in train_loader:\n","        step += 1\n","        inputs, labels, img_names = batch_data[0].to(device), batch_data[1].to(device), batch_data[2]\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_len = len(train_ds) // train_loader.batch_size\n","        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n","\n","        predicted_labels = outputs.argmax(dim=1)\n","        probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Convert raw logits to probabilities\n","\n","        # Save current epoch training results\n","        for i in range(len(img_names)):\n","            train_epoch_results.append(\n","                (img_names[i], labels[i].item(), predicted_labels[i].item(), probabilities[i].cpu().tolist())\n","            )\n","\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        num_correct = 0.0\n","        metric_count = 0\n","        val_epoch_results = []  # Store current epoch validation results\n","\n","        for val_data in val_loader:\n","            val_images, val_labels, val_img_names = val_data[0].to(device), val_data[1].to(device), val_data[2]\n","            with torch.no_grad():\n","                val_outputs = model(val_images)\n","                predicted_val_labels = val_outputs.argmax(dim=1)\n","                probabilities = torch.nn.functional.softmax(val_outputs, dim=1)  # Convert raw logits to probabilities\n","                value = torch.eq(predicted_val_labels, val_labels)\n","                metric_count += len(value)\n","                num_correct += value.sum().item()\n","\n","                # Save current epoch validation results\n","                for i in range(len(val_img_names)):\n","                    val_epoch_results.append(\n","                        (val_img_names[i], val_labels[i].item(), predicted_val_labels[i].item(), probabilities[i].cpu().tolist())\n","                    )\n","\n","        metric = num_correct / metric_count\n","        metric_values.append(metric)\n","\n","        # If current accuracy is the best, update best model results\n","        if metric > best_metric:\n","            best_metric = metric\n","            best_metric_epoch = epoch + 1\n","            torch.save(model.state_dict(), \"best_metric_model_classification3d_dense.pth\")\n","            print(\"saved new best metric model\")\n","\n","            # Update best training and validation results\n","            best_train_results = train_epoch_results\n","            best_val_results = val_epoch_results\n","\n","        print(f\"Current epoch: {epoch + 1} current accuracy: {metric:.4f}\")\n","        print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n","        writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n","\n","print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","\n","# Print best epoch results\n","print(\"\\nBest epoch train results:\")\n","for img_name, true_label, pred_label, probabilities in best_train_results:\n","    print(f\"Train Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {probabilities}\")\n","\n","print(\"\\nBest epoch validation results:\")\n","for img_name, true_label, pred_label, probabilities in best_val_results:\n","    print(f\"Val Image: {img_name}, True Label: {true_label}, Predicted Label: {pred_label}, Probabilities: {probabilities}\")\n","\n","writer.close()"],"metadata":{"id":"rxdPTJZJHfV2"},"execution_count":null,"outputs":[]}]}